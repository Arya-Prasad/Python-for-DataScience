{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# urllib.request.urlretrieve('ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt','stations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACW00011604  17.1167  -61.7833   10.1    ST JOHNS COOLIDGE FLD                       \\n',\n",
       " 'ACW00011647  17.1333  -61.7833   19.2    ST JOHNS                                    \\n',\n",
       " 'AE000041196  25.3330   55.5170   34.0    SHARJAH INTER. AIRP            GSN     41196\\n',\n",
       " 'AEM00041194  25.2550   55.3640   10.4    DUBAI INTL                             41194\\n',\n",
       " 'AEM00041217  24.4330   54.6510   26.8    ABU DHABI INTL                         41217\\n',\n",
       " 'AEM00041218  24.2620   55.6090  264.9    AL AIN INTL                            41218\\n',\n",
       " 'AF000040930  35.3170   69.0170 3366.0    NORTH-SALANG                   GSN     40930\\n',\n",
       " 'AFM00040938  34.2100   62.2280  977.2    HERAT                                  40938\\n',\n",
       " 'AFM00040948  34.5660   69.2120 1791.3    KABUL INTL                             40948\\n',\n",
       " 'AFM00040990  31.5000   65.8500 1010.0    KANDAHAR AIRPORT                       40990\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('stations.txt','r').readlines()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = {}\n",
    "\n",
    "for line in open('stations.txt','r'):\n",
    "    if 'GSN' in line:\n",
    "        fields = line.split()\n",
    "        \n",
    "        stations[fields[0]] = ' '.join(fields[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findstation(s):\n",
    "    found = {code: name for code,name in stations.items() if s in name}\n",
    "    print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USW00022536': 'HI LIHUE WSO AP 1020.1 GSN 91165'}\n"
     ]
    }
   ],
   "source": [
    "findstation('LIHUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USW00023188': 'CA SAN DIEGO LINDBERGH FLD GSN 72290'}\n"
     ]
    }
   ],
   "source": [
    "findstation('SAN DIEGO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USW00014922': 'MN MINNEAPOLIS/ST PAUL AP GSN HCN 72658'}\n"
     ]
    }
   ],
   "source": [
    "findstation('MINNEAPOLIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RSM00030710': 'IRKUTSK GSN 30710'}\n"
     ]
    }
   ],
   "source": [
    "findstation('IRKUTSK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datastations = ['USW00022536','USW00023188','USW00014922','RSM00030710']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the temperature data\n",
    "\n",
    "1. Parsing a fixed-field text file using np.genfromtxt\n",
    "\n",
    "2. Using ranges of NumPy datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USW00022536195002TMAX  256  0  256  0  256  0  267  0  217  0  228  0  256  0  272  0  256  0  256  0  256  0  244  0  256  0  256  0  244  0  244  0  250  0  256  0  239  0  250  0  256  0  256  0  267  0  261  0  267  0  267  0  261  0  261  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002TMIN  178  0  156  0  161  0  167  0  167  0  167  0  189  0  211  0  206  0  217  0  217  0  211  0  200  0  200  0  206  0  183  0  206  0  206  0  206  0  194  0  206  0  200  0  206  0  200  0  211  0  183  0  172  0  200  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002PRCP    0  0    0  0    0  0    0  0  737  0  406  0   36  0   38  0    0T 0    0T 0    0  0    0T 0   18  0    5  0   10  0   18  0   15  0    5  0    0T 0    0T 0   23  0   10  0    3  0   48  0    0T 0    0T 0    0T 0    5  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002SNOW    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002SNWD    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002WT03-9999   -9999   -9999   -9999       1  0-9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002WT16-9999   -9999   -9999   -9999       1  X    1  X    1  X    1  X    1  X    1  X-9999       1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X    1  X-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195003TMAX  261  0  261  0  272  0  278  0  250  0  233  0  256  0  272  0  233  0  233  0  239  0  244  0  256  0  261  0  256  0  261  0  272  0  261  0  267  0  244  0  256  0  261  0  250  0  256  0  261  0  256  0  256  0  250  0  244  0  239  0  222  0\\n',\n",
       " 'USW00022536195003TMIN  211  0  172  0  144  0  139  0  156  0  178  0  200  0  156  0  172  0  161  0  178  0  189  0  189  0  200  0  189  0  183  0  200  0  194  0  200  0  194  0  206  0  200  0  194  0  189  0  200  0  194  0  194  0  189  0  178  0  189  0  161  0\\n',\n",
       " 'USW00022536195003PRCP    0T 0    3  0    0  0    0T 0  135  0    0T 0    0  0   41  0  876  0   30  0   20  0    0T 0    0T 0   10  0    0  0    0  0    0  0    3  0    0T 0   25  0    8  0    8  0   18  0   15  0    3  0   91  0   56  0   10  0    5  0    0T 0   61  0\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the contents of the daily weather files for station Lihue\n",
    "\n",
    "open('USW00022536.dly','r').readlines()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is described in detail in the readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['------------------------------\\n',\n",
       " 'Variable   Columns   Type\\n',\n",
       " '------------------------------\\n',\n",
       " 'ID            1-11   Character\\n',\n",
       " 'YEAR         12-15   Integer\\n',\n",
       " 'MONTH        16-17   Integer\\n',\n",
       " 'ELEMENT      18-21   Character\\n',\n",
       " 'VALUE1       22-26   Integer\\n',\n",
       " 'MFLAG1       27-27   Character\\n',\n",
       " 'QFLAG1       28-28   Character\\n',\n",
       " 'SFLAG1       29-29   Character\\n',\n",
       " 'VALUE2       30-34   Integer\\n',\n",
       " 'MFLAG2       35-35   Character\\n',\n",
       " 'QFLAG2       36-36   Character\\n',\n",
       " 'SFLAG2       37-37   Character\\n',\n",
       " '  .           .          .\\n',\n",
       " '  .           .          .\\n',\n",
       " '  .           .          .\\n',\n",
       " 'VALUE31    262-266   Integer\\n',\n",
       " 'MFLAG31    267-267   Character\\n',\n",
       " 'QFLAG31    268-268   Character\\n',\n",
       " 'SFLAG31    269-269   Character\\n',\n",
       " '------------------------------\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Relevant lines of the description\n",
    "\n",
    "open('readme.txt','r').readlines()[98:121]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table describes fixed text format, but the value fields always occupy the same columns. NumPy has a special function that can read such a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first write a general call and then figure out the values for all its arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsefile(filename):\n",
    "    return np.genfromtxt(filename,  #numpy needs to be told the filename\n",
    "                         delimiter = dly_delimiter,  #the size of all fields\n",
    "                         usecols = dly_usecols,  # which columns we wish to keep\n",
    "                         dtype = dly_dtype,  #the type of all the fields\n",
    "                         names = dly_names)  #the names that we want to give to all the fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be a NumPy record array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looking at the format above...fill out the arguments\n",
    "\n",
    "dly_delimiter = [11,4,2,4] + [5,1,1,1] * 31\n",
    "dly_usecols = [1,2,3] + [4*i for i in range(1,32)]\n",
    "dly_dtype = [np.int32,np.int32,(np.str_,4)] + [np.int32] * 31\n",
    "dly_names = ['year','month','obs'] + [str(day) for day in range(1,31+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lihue = parsefile('USW00022536.dly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (1950, 2, 'TMAX',   256,   256,   256,   267,   217,   228,   256,   272,   256,   256,   256,   244,   256,   256,   244,   244,   250,   256,   239,   250,   256,   256,   267,   261,   267,   267,   261,   261, -9999, -9999, -9999),\n",
       "       (1950, 2, 'TMIN',   178,   156,   161,   167,   167,   167,   189,   211,   206,   217,   217,   211,   200,   200,   206,   183,   206,   206,   206,   194,   206,   200,   206,   200,   211,   183,   172,   200, -9999, -9999, -9999),\n",
       "       (1950, 2, 'PRCP',     0,     0,     0,     0,   737,   406,    36,    38,     0,     0,     0,     0,    18,     5,    10,    18,    15,     5,     0,     0,    23,    10,     3,    48,     0,     0,     0,     5, -9999, -9999, -9999),\n",
       "       ...,\n",
       "       (2015, 9, 'WT03', -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999,     1, -9999,     1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999),\n",
       "       (2015, 9, 'WT08', -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999,     1, -9999, -9999, -9999,     1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999,     1,     1, -9999, -9999, -9999, -9999, -9999, -9999),\n",
       "       (2015, 9, 'WT10', -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999,     1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999)],\n",
       "      dtype=[('year', '<i4'), ('month', '<i4'), ('obs', '<U4'), ('1', '<i4'), ('2', '<i4'), ('3', '<i4'), ('4', '<i4'), ('5', '<i4'), ('6', '<i4'), ('7', '<i4'), ('8', '<i4'), ('9', '<i4'), ('10', '<i4'), ('11', '<i4'), ('12', '<i4'), ('13', '<i4'), ('14', '<i4'), ('15', '<i4'), ('16', '<i4'), ('17', '<i4'), ('18', '<i4'), ('19', '<i4'), ('20', '<i4'), ('21', '<i4'), ('22', '<i4'), ('23', '<i4'), ('24', '<i4'), ('25', '<i4'), ('26', '<i4'), ('27', '<i4'), ('28', '<i4'), ('29', '<i4'), ('30', '<i4'), ('31', '<i4')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lihue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (1950, 2, 'TMAX',   256,   256,   256,   267, 217,   228,   256,   272,   256,   256,   256,   244,   256,   256,   244,   244,   250,   256,   239,   250,   256,   256,   267,   261,   267,   267,   261,   261, -9999, -9999, -9999),\n",
       "       (1950, 2, 'TMIN',   178,   156,   161,   167, 167,   167,   189,   211,   206,   217,   217,   211,   200,   200,   206,   183,   206,   206,   206,   194,   206,   200,   206,   200,   211,   183,   172,   200, -9999, -9999, -9999),\n",
       "       (1950, 2, 'PRCP',     0,     0,     0,     0, 737,   406,    36,    38,     0,     0,     0,     0,    18,     5,    10,    18,    15,     5,     0,     0,    23,    10,     3,    48,     0,     0,     0,     5, -9999, -9999, -9999),\n",
       "       (1950, 2, 'SNOW',     0,     0,     0,     0,   0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0, -9999, -9999, -9999),\n",
       "       (1950, 2, 'SNWD',     0,     0,     0,     0,   0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0, -9999, -9999, -9999),\n",
       "       (1950, 2, 'WT03', -9999, -9999, -9999, -9999,   1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999),\n",
       "       (1950, 2, 'WT16', -9999, -9999, -9999, -9999,   1,     1,     1,     1,     1,     1, -9999,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1,     1, -9999, -9999, -9999),\n",
       "       (1950, 3, 'TMAX',   261,   261,   272,   278, 250,   233,   256,   272,   233,   233,   239,   244,   256,   261,   256,   261,   272,   261,   267,   244,   256,   261,   250,   256,   261,   256,   256,   250,   244,   239,   222),\n",
       "       (1950, 3, 'TMIN',   211,   172,   144,   139, 156,   178,   200,   156,   172,   161,   178,   189,   189,   200,   189,   183,   200,   194,   200,   194,   206,   200,   194,   189,   200,   194,   194,   189,   178,   189,   161),\n",
       "       (1950, 3, 'PRCP',     0,     3,     0,     0, 135,     0,     0,    41,   876,    30,    20,     0,     0,    10,     0,     0,     0,     3,     0,    25,     8,     8,    18,    15,     3,    91,    56,    10,     5,     0,    61)],\n",
       "      dtype=[('year', '<i4'), ('month', '<i4'), ('obs', '<U4'), ('1', '<i4'), ('2', '<i4'), ('3', '<i4'), ('4', '<i4'), ('5', '<i4'), ('6', '<i4'), ('7', '<i4'), ('8', '<i4'), ('9', '<i4'), ('10', '<i4'), ('11', '<i4'), ('12', '<i4'), ('13', '<i4'), ('14', '<i4'), ('15', '<i4'), ('16', '<i4'), ('17', '<i4'), ('18', '<i4'), ('19', '<i4'), ('20', '<i4'), ('21', '<i4'), ('22', '<i4'), ('23', '<i4'), ('24', '<i4'), ('25', '<i4'), ('26', '<i4'), ('27', '<i4'), ('28', '<i4'), ('29', '<i4'), ('30', '<i4'), ('31', '<i4')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lihue[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a numpy record array with all the information contained in the original file, but needs to be made into a better form\n",
    "\n",
    "The temperatures for all the days of the month sit on the same row, which is inconvenient because different months have different number of days. Instead, each day should have a separate row. And also each datapoint needs to be associated with a proper NumPy datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unroll(record):\n",
    "    \n",
    "    #begin by creating a range of dates that correspond to a row\n",
    "    #specify the beginning of the month by including only the year and the month in a string fed to the datetime64 object.\n",
    "    #>>> print '{0:03d}, {1:03d}'.format(1,2) >>> 001, 002 \n",
    "    startdate = np.datetime64('{}-{:02}'.format(record['year'],record['month']))\n",
    "    \n",
    "    #Then create a range of dated using numpy arange starting at the \n",
    "    #start date, ending at the start date plus one month and with a step of one day.\n",
    "    dates = np.arange(startdate,startdate + np.timedelta64(1,'M'),np.timedelta64(1,'D'))\n",
    "    \n",
    "    #Next, collect the data for the days from the record\n",
    "    #Specify the field for which we're going to extract the data by enclosing dates in\n",
    "    #enumerate by looping over an index and a date at the same time.\n",
    "    #Divide each datapoint by 10 since temps are specified in tens of degrees.\n",
    "    \n",
    "    rows = [(date,record[str(i+1)]/10) for i,date in enumerate(dates)]\n",
    "    #return rows ---try this\n",
    "    \n",
    "    return np.array(rows,dtype = [('date','M8[D]'),('value','d')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('1950-02-01',  25.6), ('1950-02-02',  25.6), ('1950-02-03',  25.6),\n",
       "       ('1950-02-04',  26.7), ('1950-02-05',  21.7), ('1950-02-06',  22.8),\n",
       "       ('1950-02-07',  25.6), ('1950-02-08',  27.2), ('1950-02-09',  25.6),\n",
       "       ('1950-02-10',  25.6), ('1950-02-11',  25.6), ('1950-02-12',  24.4),\n",
       "       ('1950-02-13',  25.6), ('1950-02-14',  25.6), ('1950-02-15',  24.4),\n",
       "       ('1950-02-16',  24.4), ('1950-02-17',  25. ), ('1950-02-18',  25.6),\n",
       "       ('1950-02-19',  23.9), ('1950-02-20',  25. ), ('1950-02-21',  25.6),\n",
       "       ('1950-02-22',  25.6), ('1950-02-23',  26.7), ('1950-02-24',  26.1),\n",
       "       ('1950-02-25',  26.7), ('1950-02-26',  26.7), ('1950-02-27',  26.1),\n",
       "       ('1950-02-28',  26.1)],\n",
       "      dtype=[('date', '<M8[D]'), ('value', '<f8')])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unroll(lihue[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to take all the months contained in a file and concatenate them together into a single NumPy record array.\n",
    "We also want to select a single observable, such as  minimum temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a list comprehension containing the unrolled rows for each row of the parsed file.\n",
    "#And select only those that contain our desired observable\n",
    "\n",
    "def getobs(filename,obs):\n",
    "    return np.concatenate([unroll(row) for row in parsefile(filename) if row[2] == obs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('1950-02-01',   17.8), ('1950-02-02',   15.6),\n",
       "       ('1950-02-03',   16.1), ..., ('2015-09-28', -999.9),\n",
       "       ('2015-09-29', -999.9), ('2015-09-30', -999.9)],\n",
       "      dtype=[('date', '<M8[D]'), ('value', '<f8')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getobs('USW00022536.dly','TMIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
